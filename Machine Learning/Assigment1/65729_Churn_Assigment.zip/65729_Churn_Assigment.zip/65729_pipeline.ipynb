{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      1.00      0.98       512\n",
      "        True       0.97      0.83      0.90        88\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.97      0.91      0.94       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "Accuracy: 0.9716666666666667\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from feature_engineering import apply_feature_engineering  # Import des fonctions de feature engineering\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('2767ML_assignment1_data.csv')\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_cols = ['State', 'International plan', 'Voice mail plan']\n",
    "numerical_cols = ['Account length', 'Number vmail messages', 'Customer service calls', \n",
    "                  'MonthlyCharges', 'TotalMinutes', 'TotalCalls',\n",
    "                  'DayMinutesPct', 'EveMinutesPct', 'NightMinutesPct', 'IntlMinutesPct',\n",
    "                  'DayChargesPct', 'EveChargesPct', 'NightChargesPct', 'IntlChargesPct',\n",
    "                  'DayCallsPct', 'EveCallsPct', 'NightCallsPct', 'IntlCallsPct']\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=['Churn'])  # Features\n",
    "y = df['Churn']  # Target\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply FunctionTransformer to apply the feature engineering function\n",
    "feature_transformer = FunctionTransformer(apply_feature_engineering)\n",
    "\n",
    "# Create a ColumnTransformer to apply different preprocessing to different columns\n",
    "preprocessing_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Scale numerical features\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        # One-hot encode categorical features\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Créer un pipeline unique qui inclut le feature engineering, le prétraitement et le modèle XGBoost\n",
    "full_pipeline = Pipeline([\n",
    "    ('feature_engineering', feature_transformer),  # Custom feature engineering\n",
    "    ('preprocessor', preprocessing_pipeline),  # Prétraitement (scaling + encoding)\n",
    "    ('classifier', XGBClassifier(random_state=42))  # Modèle XGBoost\n",
    "])\n",
    "\n",
    "# Entraîner le pipeline unique sur les données d'entraînement\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Sauvegarder le pipeline unique dans un fichier pickle\n",
    "with open('full_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(full_pipeline, f)\n",
    "\n",
    "# Appliquer le pipeline unique aux données de test pour évaluer le modèle\n",
    "y_pred = full_pipeline.predict(X_test)\n",
    "\n",
    "# Afficher les métriques d'évaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Predictions: [1 0 0]\n",
      "Churn Probabilities: [0.9996063  0.9367366  0.00161879]\n",
      "Churn Predictions (threshold = 0.99):  [1 0 0]\n",
      "Churn Predictions (threshold = 0.5):  [1 1 0]\n",
      "Churn Predictions (threshold = 0.3):  [1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from feature_engineering import apply_feature_engineering\n",
    "\n",
    "# Charger les nouvelles données\n",
    "new_data = pd.read_excel(\"2767ML_assignment1_externalvalidation_data_toStudents.xls\")\n",
    "\n",
    "# Charger le pipeline unique (prétraitement + modèle XGBoost)\n",
    "with open('full_pipeline.pkl', 'rb') as f:\n",
    "    full_pipeline = pickle.load(f)\n",
    "\n",
    "# Faire des prédictions avec le pipeline unique\n",
    "predictions = full_pipeline.predict(new_data)\n",
    "\n",
    "# Obtenir les probabilités prédites\n",
    "probabilities = full_pipeline.predict_proba(new_data)[:, 1]  # Probabilités pour la classe 1\n",
    "\n",
    "# Afficher les prédictions\n",
    "print(\"Churn Predictions:\", predictions)\n",
    "print(\"Churn Probabilities:\", probabilities)\n",
    "\n",
    "# Apply different thresholds\n",
    "thresholds = [0.99, 0.5, 0.3]\n",
    "for threshold in thresholds:\n",
    "    predictions = (probabilities > threshold).astype(int)\n",
    "    print(f\"Churn Predictions (threshold = {threshold}): \", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
