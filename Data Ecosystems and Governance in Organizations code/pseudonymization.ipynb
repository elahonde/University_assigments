{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-method Pseudonymization\n",
    "\n",
    "This notebook demonstrates several ways to pseudonymize sensitive data:\n",
    "\n",
    "1. **Tokenization** – Replace identifiers with random tokens, managed in dictionaries (mapping tables).\n",
    "2. **Hashing** – Use a one-way cryptographic hash function (SHA-256).\n",
    "3. **Encryption** – Use symmetric encryption (Fernet) for reversible pseudonymization.\n",
    "4. **Hybrid** – Combine partial hashing and random tokens for custom use cases.\n",
    "\n",
    "We'll explore the trade-offs in re-identification risk, key management, and data utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Necessary Libraries (if needed)\n",
    "\n",
    "Make sure you have the following installed:\n",
    "- [pandas](https://pandas.pydata.org/): For handling tabular data\n",
    "- [cryptography](https://cryptography.io/en/latest/): For encryption (Fernet)\n",
    "\n",
    "```bash\n",
    "pip install pandas cryptography\n",
    "```\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas cryptography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Imports & Setup\n",
    "\n",
    "We'll import the libraries we need, then create a simple dataset to work with.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import hashlib\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# Create a small synthetic dataset\n",
    "data = {\n",
    "    'Name': [\n",
    "        'Alice Johnson',\n",
    "        'Bob Smith',\n",
    "        'Charlie Li',\n",
    "        'Alice Johnson',\n",
    "        'Dana White'\n",
    "    ],\n",
    "    'Email': [\n",
    "        'alice.j@example.com',\n",
    "        'bob.s@example.com',\n",
    "        'charlie.l@example.com',\n",
    "        'alice.j@example.com',\n",
    "        'dana.w@example.com'\n",
    "    ],\n",
    "    'Phone': [\n",
    "        '123-456-7890',\n",
    "        '555-123-4567',\n",
    "        '987-654-3210',\n",
    "        '123-456-7890',\n",
    "        '555-987-6543'\n",
    "    ],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Houston'],\n",
    "    'Age': [29, 34, 22, 29, 45]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print('Original DataFrame:')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tokenization\n",
    "\n",
    "### Description\n",
    "- We assign random tokens to each unique value in a column.\n",
    "- A dictionary (mapping table) tracks which real values map to which tokens.\n",
    "- If the same real value appears multiple times, it maps to the same token.\n",
    "\n",
    "**Pros**:\n",
    "- Can still recognize repeated occurrences of the same entity.\n",
    "- Re-identification is possible only if you have the mapping dictionary.\n",
    "\n",
    "**Cons**:\n",
    "- Completely reversible if the mapping (token dictionary) is compromised.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) TOKENIZATION\n",
    "\n",
    "# Helper function to generate random alphanumeric tokens\n",
    "def generate_random_token(length=10):\n",
    "    chars = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(chars) for _ in range(length))\n",
    "\n",
    "# Dictionaries for storing the real-value-to-token mappings\n",
    "name_token_map = {}\n",
    "email_token_map = {}\n",
    "phone_token_map = {}\n",
    "\n",
    "def get_token(mapping_dict, real_value):\n",
    "    \"\"\"Return the token for real_value, generating one if needed.\"\"\"\n",
    "    if real_value not in mapping_dict:\n",
    "        mapping_dict[real_value] = generate_random_token()\n",
    "    return mapping_dict[real_value]\n",
    "\n",
    "df['Name_TOKEN'] = df['Name'].apply(lambda x: get_token(name_token_map, x))\n",
    "df['Email_TOKEN'] = df['Email'].apply(lambda x: get_token(email_token_map, x))\n",
    "df['Phone_TOKEN'] = df['Phone'].apply(lambda x: get_token(phone_token_map, x))\n",
    "\n",
    "print('\\n--- After Tokenization ---')\n",
    "print(df[['Name', 'Name_TOKEN', 'Email', 'Email_TOKEN', 'Phone', 'Phone_TOKEN', 'City', 'Age']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Hashing (SHA-256)\n",
    "\n",
    "### Description\n",
    "- Convert each identifier into a **one-way** hash.\n",
    "- Here, we add a salt (a constant string) to reduce the effectiveness of simple dictionary or rainbow table attacks.\n",
    "- Still, if the underlying value space is small (e.g., phone numbers), brute force is possible.\n",
    "\n",
    "**Pros**:\n",
    "- Irreversible (assuming large, unpredictable inputs).\n",
    "- No secret key needed for re-identification (you simply cannot re-identify unless you guess the original).\n",
    "\n",
    "**Cons**:\n",
    "- If an attacker can guess or brute force the original values, they can confirm matches.\n",
    "- Does not allow re-identification for legitimate business needs (like emailing the user).\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) HASHING\n",
    "\n",
    "def hash_value(value, salt='RANDOM_SALT_123'):\n",
    "    \"\"\"Return the SHA-256 hash of (salt + value).\"\"\"\n",
    "    to_hash = (salt + value).encode('utf-8')\n",
    "    return hashlib.sha256(to_hash).hexdigest()\n",
    "\n",
    "df['Name_HASH'] = df['Name'].apply(lambda x: hash_value(x))\n",
    "df['Email_HASH'] = df['Email'].apply(lambda x: hash_value(x))\n",
    "df['Phone_HASH'] = df['Phone'].apply(lambda x: hash_value(x))\n",
    "\n",
    "print('\\n--- After Hashing ---')\n",
    "print(df[['Name', 'Name_HASH', 'Email', 'Email_HASH', 'Phone', 'Phone_HASH', 'City', 'Age']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Encryption (Fernet)\n",
    "\n",
    "### Description\n",
    "- Use a **symmetric** encryption key to encrypt identifiers.\n",
    "- Fernet automatically handles random IVs, but the same plaintext may produce different ciphertext each time.\n",
    "- If you need deterministic encryption (same input always yields the same output), you have to configure it differently or use a separate approach.\n",
    "\n",
    "**Pros**:\n",
    "- *Reversible* if you have the key, so you can restore original values.\n",
    "- Good for data that occasionally needs to be de-anonymized (e.g., customer service).\n",
    "\n",
    "**Cons**:\n",
    "- Requires **key management** (if the key is exposed, data is compromised).\n",
    "- If deterministic encryption is desired for matching records, additional steps are needed.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) ENCRYPTION\n",
    "\n",
    "# Generate or load a key\n",
    "key = Fernet.generate_key()\n",
    "fernet = Fernet(key)\n",
    "\n",
    "def encrypt_value(value):\n",
    "    \"\"\"Encrypt a string using Fernet.\"\"\"\n",
    "    token = fernet.encrypt(value.encode('utf-8'))\n",
    "    return token.decode('utf-8')\n",
    "\n",
    "df['Name_ENCRYPT'] = df['Name'].apply(encrypt_value)\n",
    "df['Email_ENCRYPT'] = df['Email'].apply(encrypt_value)\n",
    "df['Phone_ENCRYPT'] = df['Phone'].apply(encrypt_value)\n",
    "\n",
    "print('\\n--- After Encryption ---')\n",
    "print(df[['Name', 'Name_ENCRYPT', 'Email', 'Email_ENCRYPT', 'Phone', 'Phone_ENCRYPT', 'City', 'Age']])\n",
    "\n",
    "# For demonstration, let's print the key, but do NOT do this in a real environment.\n",
    "print(f\"\\nEncryption Key (store securely!): {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Hybrid Approach\n",
    "\n",
    "### Description\n",
    "- Combine partial hashing, partial tokenization, or partial encryption.\n",
    "- Example: **Hash** the first half of the string, keep the second half in plaintext, then append a random suffix.\n",
    "- This can preserve partial readability (like partial phone digits) while still limiting re-identification.\n",
    "\n",
    "There are infinite variations. The point is to *balance* data utility and privacy.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) HYBRID APPROACH\n",
    "\n",
    "def hybrid_pseudonymize(value):\n",
    "    \"\"\"\n",
    "    Example: Hash the first half of the string, keep second half as is, append random token.\n",
    "    \"\"\"\n",
    "    mid = len(value) // 2\n",
    "    part_to_hash = value[:mid]\n",
    "    part_remaining = value[mid:]\n",
    "\n",
    "    hashed_part = hash_value(part_to_hash)[0:10]  # Shorten the hash for demonstration\n",
    "    random_suffix = generate_random_token(length=5)\n",
    "\n",
    "    # Combine hashed half, the un-hashed half, and a random suffix\n",
    "    return f\"{hashed_part}_{part_remaining}_{random_suffix}\"\n",
    "\n",
    "df['Name_HYBRID'] = df['Name'].apply(hybrid_pseudonymize)\n",
    "df['Email_HYBRID'] = df['Email'].apply(hybrid_pseudonymize)\n",
    "df['Phone_HYBRID'] = df['Phone'].apply(hybrid_pseudonymize)\n",
    "\n",
    "print('\\n--- After Hybrid Approach ---')\n",
    "print(df[['Name', 'Name_HYBRID', 'Email', 'Email_HYBRID', 'Phone', 'Phone_HYBRID', 'City', 'Age']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Consolidated View\n",
    "\n",
    "We can look at our DataFrame with **all** pseudonymized columns side by side.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = [\n",
    "    'Name', 'Name_TOKEN', 'Name_HASH', 'Name_ENCRYPT', 'Name_HYBRID',\n",
    "    'Email', 'Email_TOKEN', 'Email_HASH', 'Email_ENCRYPT', 'Email_HYBRID',\n",
    "    'Phone', 'Phone_TOKEN', 'Phone_HASH', 'Phone_ENCRYPT', 'Phone_HYBRID',\n",
    "    'City', 'Age'\n",
    "]\n",
    "\n",
    "print('\\n--- Full Comparison ---')\n",
    "print(df[all_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Mapping Tables & Key Management\n",
    "\n",
    "For demonstration, let's print out our mapping dictionaries. In a real-world scenario:\n",
    "- Store mappings in a separate **secure** data store.\n",
    "- Limit read/write access to only the systems that need to re-identify (if applicable).\n",
    "- **Encrypt** or protect these mappings at rest (e.g., using AWS KMS, HashiCorp Vault, etc.).\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n--- TOKEN MAPPINGS ---')\n",
    "print('Name Token Map:')\n",
    "for real_name, token in name_token_map.items():\n",
    "    print(f\"  {real_name} -> {token}\")\n",
    "\n",
    "print('\\nEmail Token Map:')\n",
    "for real_email, token in email_token_map.items():\n",
    "    print(f\"  {real_email} -> {token}\")\n",
    "\n",
    "print('\\nPhone Token Map:')\n",
    "for real_phone, token in phone_token_map.items():\n",
    "    print(f\"  {real_phone} -> {token}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "**Tokenization**:\n",
    "- Useful if you need to track repeated occurrences of the same individual.\n",
    "- Reversible by design (if mapping dictionary is available).\n",
    "\n",
    "**Hashing**:\n",
    "- One-way. Irreversible without brute force or guess.\n",
    "- May be vulnerable for small/guessable input spaces.\n",
    "\n",
    "**Encryption** (Fernet):\n",
    "- Reversible if you have the key.\n",
    "- Strong security but requires strict key management.\n",
    "\n",
    "**Hybrid**:\n",
    "- Highly customizable.\n",
    "- Careful not to reveal too much partial info.\n",
    "\n",
    "In production:\n",
    "- Use a **secrets manager** (e.g., AWS KMS, HashiCorp Vault) to store encryption keys.\n",
    "- Restrict who can access token dictionaries or decryption services.\n",
    "- Consider your threat model, regulatory environment, and data usage needs.\n",
    "\n",
    "This completes the multi-method pseudonymization example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
