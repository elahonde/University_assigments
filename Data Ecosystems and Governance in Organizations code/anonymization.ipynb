{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Anonymity, L-Diversity, T-Closeness Demonstration\n",
    "\n",
    "This notebook shows how to:\n",
    "\n",
    "- **k-Anonymity**: Ensure each group of quasi-identifiers has *at least* k rows.\n",
    "- **l-Diversity**: Ensure each group of quasi-identifiers has *l* distinct sensitive values.\n",
    "- **t-Closeness**: Briefly check how similar each group's sensitive-attribute distribution is to the overall distribution.\n",
    "\n",
    "We will:\n",
    "1. Create or load a synthetic DataFrame.\n",
    "2. Define generalization functions (for Age and ZipCode).\n",
    "3. Check k-anonymity.\n",
    "4. Check l-diversity.\n",
    "5. Sketch a t-closeness check.\n",
    "6. Summarize the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create or Load Synthetic Data\n",
    "\n",
    "We create a simple dataset with three columns:\n",
    "- **Age** (numeric)\n",
    "- **ZipCode** (string)\n",
    "- **Disease** (string, treated as the sensitive attribute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "data = {\n",
    "    'Age': [25, 27, 27, 34, 35, 36, 36, 45, 46, 52, 52, 52],\n",
    "    'ZipCode': ['12345','12345','12344','12345','12349','12349','12349','12350','12350','12350','12351','12351'],\n",
    "    'Disease': ['Flu','Cold','Flu','Diabetes','Cold','Flu','Cold','Diabetes','Flu','Flu','Cold','Flu']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\\n\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generalization Functions\n",
    "\n",
    "We define functions to **bin** the Age values into decade-based ranges (e.g., 20â€“29) and to **truncate** the ZipCode to the first 3 characters. These transformations reduce granularity, helping to form larger groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_age(age):\n",
    "    start = (age // 10) * 10\n",
    "    return f\"{start}-{start+9}\"\n",
    "\n",
    "def truncate_zip(zipcode, keep=3):\n",
    "    return zipcode[:keep]\n",
    "\n",
    "df['Age_Bin'] = df['Age'].apply(bin_age)\n",
    "df['Zip_Trunc'] = df['ZipCode'].apply(lambda z: truncate_zip(z, 3))\n",
    "print(\"\\nDataFrame after basic generalization:\\n\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: k-Anonymity\n",
    "\n",
    "To check **k-Anonymity**, we group the DataFrame by the quasi-identifiers (`Age_Bin`, `Zip_Trunc`) and verify whether each group has at least `k` records. If a group has fewer than `k` rows, it fails.\n",
    "\n",
    "You could then remove (suppress) or further generalize those groups in a real-world scenario, but we'll only identify them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_k_anonymity(df, quasi_identifiers, k):\n",
    "    grouped = df.groupby(quasi_identifiers).size()\n",
    "    failed_groups = grouped[grouped < k]\n",
    "    return failed_groups\n",
    "\n",
    "k = 3\n",
    "qi_cols = ['Age_Bin', 'Zip_Trunc']\n",
    "failed_k = check_k_anonymity(df, qi_cols, k)\n",
    "print(f\"\\nChecking for k-anonymity with k={k}...\")\n",
    "if failed_k.empty:\n",
    "    print(\"All groups satisfy k-anonymity!\")\n",
    "else:\n",
    "    print(\"Groups that fail k-anonymity:\")\n",
    "    print(failed_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: l-Diversity\n",
    "\n",
    "To check **l-Diversity**, we verify that within each group of quasi-identifiers, the **sensitive attribute** column (here `Disease`) contains *at least* `l` different values. If all records in a group share the same disease, for example, that group fails l-diversity.\n",
    "\n",
    "We'll use `l = 2` for demonstration. You could also explore entropy- or recursive-based l-diversity, but we'll keep it simple here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_l_diversity(df, quasi_identifiers, sensitive_col, l):\n",
    "    group_data = df.groupby(quasi_identifiers)[sensitive_col].apply(lambda x: len(set(x)))\n",
    "    failed_groups = group_data[group_data < l]\n",
    "    return failed_groups\n",
    "\n",
    "l = 2\n",
    "failed_l = check_l_diversity(df, qi_cols, 'Disease', l)\n",
    "print(f\"\\nChecking for l-diversity with l={l}...\")\n",
    "if failed_l.empty:\n",
    "    print(\"All groups satisfy l-diversity!\")\n",
    "else:\n",
    "    print(\"Groups that fail l-diversity (distinct count < l):\")\n",
    "    print(failed_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: t-Closeness (Brief Sketch)\n",
    "\n",
    "We compare each group's distribution of `Disease` to the **global** distribution of `Disease`. If the difference (using Total Variation Distance here) is above a threshold `t`, the group fails t-closeness.\n",
    "\n",
    "More sophisticated distance metrics (like Earth Mover's Distance) or advanced definitions can be used in real applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distribution(series):\n",
    "    c = Counter(series)\n",
    "    total = sum(c.values())\n",
    "    return {k: v / total for k, v in c.items()}\n",
    "\n",
    "def total_variation_distance(dist1, dist2):\n",
    "    all_keys = set(dist1.keys()) | set(dist2.keys())\n",
    "    return sum(abs(dist1.get(k, 0) - dist2.get(k, 0)) for k in all_keys)\n",
    "\n",
    "global_dist = compute_distribution(df['Disease'])\n",
    "t = 0.2\n",
    "print(f\"\\nChecking t-closeness with t={t}...\")\n",
    "grouped = df.groupby(qi_cols)['Disease']\n",
    "violations = []\n",
    "for group_vals, diseases in grouped:\n",
    "    gd = compute_distribution(diseases)\n",
    "    distance = total_variation_distance(gd, global_dist)\n",
    "    if distance > t:\n",
    "        violations.append((group_vals, distance))\n",
    "\n",
    "if not violations:\n",
    "    print(\"All groups satisfy t-closeness!\")\n",
    "else:\n",
    "    print(\"Groups that fail t-closeness (TVD > t):\")\n",
    "    for group_vals, dist_val in violations:\n",
    "        print(f\"  {group_vals}: TVD={dist_val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Conclusion\n",
    "\n",
    "1. **k-Anonymity** checks the **size** of each group.\n",
    "2. **l-Diversity** checks the **variety** of sensitive values in each group.\n",
    "3. **t-Closeness** checks how closely each group's **distribution** of sensitive values matches the overall distribution.\n",
    "\n",
    "In practice, you would iteratively **generalize or suppress** to meet these thresholds while balancing data **utility** and **privacy**. More advanced techniques (like **entropy l-diversity**, **recursive l-diversity**, or **strict** t-closeness definitions) can further reduce re-identification risks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
